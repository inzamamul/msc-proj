{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch data[0] is : [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "image data[0] is :  [ array([[128, 126, 125, 123, 123, 126, 129, 129, 128, 127, 126, 126, 126,\n",
      "        128, 129, 128, 126, 123, 124, 126, 128, 127, 125, 125, 127, 129,\n",
      "        130, 130, 129, 129],\n",
      "       [127, 126, 125, 124, 124, 126, 129, 129, 129, 128, 127, 127, 127,\n",
      "        129, 130, 129, 127, 125, 125, 127, 128, 127, 125, 125, 127, 129,\n",
      "        130, 130, 129, 129],\n",
      "       [126, 126, 125, 125, 126, 127, 129, 130, 131, 131, 130, 130, 130,\n",
      "        131, 132, 131, 130, 128, 128, 128, 128, 128, 126, 126, 127, 128,\n",
      "        129, 129, 129, 129],\n",
      "       [125, 125, 126, 128, 129, 129, 130, 131, 133, 134, 134, 133, 133,\n",
      "        133, 134, 134, 134, 133, 133, 131, 130, 129, 128, 128, 128, 127,\n",
      "        128, 128, 128, 128],\n",
      "       [126, 127, 128, 130, 131, 131, 132, 133, 134, 137, 137, 138, 138,\n",
      "        138, 139, 139, 141, 140, 138, 135, 132, 131, 130, 130, 128, 127,\n",
      "        127, 128, 128, 128],\n",
      "       [128, 129, 130, 132, 132, 132, 133, 133, 134, 137, 138, 140, 141,\n",
      "        142, 143, 144, 145, 144, 142, 138, 135, 134, 132, 131, 129, 127,\n",
      "        126, 127, 128, 128],\n",
      "       [131, 131, 132, 133, 133, 134, 134, 134, 134, 135, 137, 139, 140,\n",
      "        141, 142, 144, 145, 145, 144, 141, 139, 137, 135, 133, 130, 128,\n",
      "        127, 127, 128, 128],\n",
      "       [131, 131, 133, 134, 134, 135, 134, 134, 134, 135, 134, 135, 135,\n",
      "        135, 136, 139, 141, 144, 144, 144, 143, 141, 138, 134, 131, 129,\n",
      "        127, 127, 127, 128],\n",
      "       [130, 130, 133, 135, 136, 136, 134, 135, 135, 133, 131, 127, 124,\n",
      "        123, 124, 127, 132, 138, 142, 145, 145, 144, 141, 137, 133, 130,\n",
      "        128, 126, 126, 126],\n",
      "       [128, 129, 132, 135, 137, 136, 134, 134, 134, 131, 126, 119, 113,\n",
      "        110, 110, 114, 120, 129, 137, 143, 146, 147, 145, 141, 137, 133,\n",
      "        129, 126, 125, 125],\n",
      "       [127, 128, 131, 135, 137, 136, 133, 133, 132, 128, 121, 113, 105,\n",
      "         99,  98, 102, 110, 121, 131, 139, 145, 149, 149, 146, 142, 136,\n",
      "        130, 126, 124, 124],\n",
      "       [127, 128, 131, 135, 136, 135, 132, 130, 128, 123, 116, 107,  98,\n",
      "         91,  87,  90,  98, 109, 121, 131, 141, 149, 152, 151, 147, 140,\n",
      "        131, 126, 124, 123],\n",
      "       [128, 129, 131, 134, 135, 134, 131, 127, 123, 116, 111, 102,  93,\n",
      "         82,  75,  74,  81,  93, 106, 120, 134, 146, 153, 153, 149, 141,\n",
      "        132, 127, 124, 123],\n",
      "       [131, 132, 132, 133, 132, 131, 128, 124, 117, 110, 105,  97,  86,\n",
      "         72,  61,  56,  60,  72,  89, 108, 127, 142, 151, 152, 149, 141,\n",
      "        133, 128, 126, 125],\n",
      "       [133, 134, 133, 132, 131, 130, 127, 122, 114, 106, 101,  94,  82,\n",
      "         65,  51,  42,  44,  55,  74,  97, 119, 137, 148, 150, 148, 140,\n",
      "        133, 130, 127, 127],\n",
      "       [134, 134, 133, 132, 131, 130, 128, 123, 113, 105, 100,  93,  81,\n",
      "         64,  50,  39,  37,  46,  64,  88, 113, 133, 145, 148, 147, 140,\n",
      "        133, 130, 128, 127],\n",
      "       [132, 133, 133, 133, 134, 132, 130, 126, 117, 109, 102,  94,  84,\n",
      "         70,  58,  47,  43,  48,  63,  86, 109, 130, 143, 148, 147, 141,\n",
      "        134, 130, 128, 126],\n",
      "       [130, 131, 132, 134, 136, 135, 133, 130, 124, 116, 108,  97,  87,\n",
      "         78,  70,  63,  58,  61,  73,  91, 111, 130, 143, 148, 148, 142,\n",
      "        135, 130, 127, 125],\n",
      "       [129, 131, 132, 134, 136, 136, 135, 134, 132, 125, 114, 100,  89,\n",
      "         82,  79,  77,  76,  80,  89, 103, 117, 132, 143, 148, 148, 142,\n",
      "        135, 130, 127, 125],\n",
      "       [129, 130, 132, 134, 136, 135, 135, 137, 140, 135, 122, 105,  93,\n",
      "         87,  88,  91,  95, 101, 109, 118, 127, 137, 144, 146, 146, 141,\n",
      "        135, 130, 127, 125],\n",
      "       [129, 130, 132, 134, 135, 135, 135, 139, 144, 142, 131, 116, 104,\n",
      "         99, 101, 106, 113, 120, 127, 133, 136, 141, 144, 144, 143, 139,\n",
      "        134, 130, 127, 126],\n",
      "       [128, 129, 131, 133, 135, 135, 135, 140, 145, 147, 141, 132, 124,\n",
      "        119, 119, 122, 128, 134, 139, 143, 144, 144, 143, 141, 139, 136,\n",
      "        132, 129, 127, 127],\n",
      "       [126, 127, 130, 133, 135, 134, 135, 139, 143, 148, 149, 147, 145,\n",
      "        141, 138, 137, 138, 142, 145, 147, 147, 145, 141, 137, 135, 132,\n",
      "        130, 129, 128, 127],\n",
      "       [126, 127, 129, 132, 134, 134, 135, 137, 140, 145, 150, 154, 155,\n",
      "        152, 148, 145, 143, 144, 146, 147, 146, 143, 138, 134, 131, 129,\n",
      "        127, 128, 128, 128],\n",
      "       [128, 128, 129, 131, 132, 132, 134, 136, 137, 141, 145, 150, 153,\n",
      "        153, 150, 148, 145, 145, 145, 145, 143, 140, 135, 131, 128, 127,\n",
      "        126, 127, 128, 129],\n",
      "       [130, 130, 129, 129, 130, 131, 133, 133, 134, 136, 138, 141, 143,\n",
      "        145, 145, 145, 143, 142, 141, 140, 138, 135, 132, 129, 126, 125,\n",
      "        125, 127, 128, 129],\n",
      "       [130, 130, 129, 128, 128, 129, 131, 130, 131, 132, 132, 133, 135,\n",
      "        137, 138, 138, 137, 135, 134, 133, 132, 130, 129, 127, 126, 125,\n",
      "        125, 127, 128, 129],\n",
      "       [128, 128, 128, 127, 127, 128, 129, 128, 130, 130, 131, 132, 132,\n",
      "        134, 134, 133, 132, 130, 130, 129, 128, 127, 127, 126, 125, 125,\n",
      "        125, 127, 127, 128],\n",
      "       [127, 127, 127, 127, 127, 127, 127, 127, 129, 130, 131, 132, 132,\n",
      "        132, 131, 129, 128, 127, 127, 126, 126, 126, 125, 125, 125, 126,\n",
      "        126, 127, 127, 127],\n",
      "       [126, 126, 127, 127, 127, 127, 126, 126, 129, 130, 131, 132, 132,\n",
      "        131, 129, 127, 126, 125, 126, 125, 125, 125, 124, 125, 125, 126,\n",
      "        126, 127, 127, 127]], dtype=uint8)\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "image_data = np.load('training_np--30--30.npy')\n",
    "\n",
    "# print len(image_data)\n",
    "batch = mnist.train.next_batch(100)\n",
    "print \"batch data[0] is :\", batch[0]\n",
    "\n",
    "print \"image data[0] is : \", image_data[0]\n",
    "\n",
    "# todo save npy file as array[imagedata], array[labels]\n",
    "# rather than array[imagedata, labels]\n",
    "# perform batch jobs of ~20 or ~50 if more data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "#makes tf more flexible about how we structure the code \n",
    "#allows to interleave oeprations which build a computation graph with ones that run the graph \n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#build a softmax regression model\n",
    "# shape arg is optional, lets tf automatically catch bugs from inconsistent tensorshapes\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) # 28x28 pixel image = 784, None indicates frst dimension\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 10]) # one hot 10-dimensional vector indictaing which digit class (0-9)\n",
    "\n",
    "# Define weights and biases\n",
    "W = tf.Variable(tf.zeros([784, 10])) # 784 input pixels by 10 output classes\n",
    "b = tf.Variable(tf.zeros([10])) # 10 output classes\n",
    "\n",
    "\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "y = tf.matmul(x,W) + b # mutliply vectorizd input images, x, by the weight matrix W and add the bias, b\n",
    "\n",
    "# calc loss function(indicates how bad the models prediction was on a single example, try to minimize accross all the examples)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "## training (strightforward because tf knows the computation graph)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# apply gradient descent updates to the parameters\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "\n",
    "# evaluate the model\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "# determining what fraction are correct, we cast to floats and then take the mean of the numbers (i.e. True becomes 1, False becomes 0)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# print accuracy \n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "###\n",
    "###### MULTILAYER COMPUTATIONAL GRAPH\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# add bias 0.1 to avoid 'dead neurons' from using ReLU neurons/ activation functions\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution and pooling. handling the boundaries and stride sizes. This is the vanilla vesion (stride of 1, zero padding, output is same size as input)\n",
    "# pooling is plain old max pooling over 2x2 blocks\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# first convolutional layer. consists of our first convolution, followed by max pooling\n",
    "# convolution will compute 32 features for each 5x5 patch\n",
    "# weight tensor wil thus have shape of [5, 5, 1, 32] i.e. [ patch size, patch size, input channels, output channels]\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32]) # bias vector\n",
    "\n",
    "# reshape x to a 4d tensor, with the 2nd and 3rd dimensions corresponding to image width and height, last dimension is # of color channels\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# convolve x_image with the weight tesnor, add bias, apply ReLU function, then max pool\n",
    "# max pool_2x2 resizes image size to 14x14\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second convolutional layer \n",
    "# will have 64 features for each 5x5 patch\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# densely connected layer. Image size has been reduced to 7x7, we add a full_connected layer with 1024 neurons to allow processing on the entire image\n",
    "# reshape the tensor from the pooling layer into a batch of vectors, multiple by a weight matrix, add bias, apply ReLU\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# add dropout to reduce overfitting - before readout layer. Dropout only really useful in large CNNs\n",
    "# turn dropout on during training, turn it off during testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# readout layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 784)\n"
     ]
    }
   ],
   "source": [
    "batch = mnist.train.next_batch(50)\n",
    "print batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step 0, training accuracy 0.04\n",
      "\n",
      "step 50, training accuracy 0.66\n",
      "\n",
      "step 100, training accuracy 0.84\n",
      "\n",
      "step 150, training accuracy 0.94\n",
      "\n",
      "step 200, training accuracy 0.92\n",
      "\n",
      "step 250, training accuracy 0.76\n",
      "\n",
      "step 300, training accuracy 0.94\n",
      "\n",
      "step 350, training accuracy 0.98\n",
      "\n",
      "step 400, training accuracy 0.96\n",
      "\n",
      "step 450, training accuracy 0.98\n",
      "\n",
      "step 500, training accuracy 0.96\n",
      "\n",
      "step 550, training accuracy 0.96\n",
      "\n",
      "step 600, training accuracy 0.92\n",
      "\n",
      "step 650, training accuracy 0.94\n",
      "\n",
      "step 700, training accuracy 1\n",
      "\n",
      "step 750, training accuracy 0.96\n",
      "\n",
      "step 800, training accuracy 1\n",
      "\n",
      "step 850, training accuracy 0.94\n",
      "\n",
      "step 900, training accuracy 0.96\n",
      "\n",
      "step 950, training accuracy 0.94\n",
      "test accuracy 0.9676\n"
     ]
    }
   ],
   "source": [
    "# train and evalutate the model\n",
    "# \n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for i in range(1000):\n",
    "        #todo: collate image_data[0] in batches? or iterate through whole dict at once \n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 50 == 0:\n",
    "#             print batch[0][1]\n",
    "#             print batch[1][1]\n",
    "            \n",
    "            print \n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            \n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
